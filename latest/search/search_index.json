{
    "docs": [
        {
            "location": "/", 
            "text": "SOM.jl - Kohonen's self-organising maps for Julia\n\n\nThe package provides training and visualisation functions for Kohonen's self-organising maps for Julia. Training functions are implemented in pure Julia, without calling external libraries.     Visualisation is implemented by using Python's MatPlotLib.\n\n\n\n\nSelf-organising maps\n\n\nSelf-organising maps (also referred to as SOMs or \nKohonen\n maps) are artificial neural networks introduced by Teuvo Kohonen in the 1980s. Despite of their age, SOMs are still widely used as an easy and robust unsupervised learning technique for analysis and visualisation of high-dimensional data.\n\n\nThe SOM algorithm maps high-dimensional vectors into a lower-dimensional grid. Most often the target grid is two-dimensional, resulting into  intuitively interpretable maps.\n\n\nFor more details see Kohonen's papers, such as\n\n\n\n\nTeuvo Kohonen, \nBiological Cybernetics,\n \n43\n (1982) p. 59-69 and Teuvo Kohonen, \nBiological Cybernetics,\n \n44\n (1982) p. 135-140\n\n\n\n\nTechnical details and background can be found in Kohonen's still relevant technical report:\n\n\n\n\nTeuvo Kohonen, Jussi Hynninen, Jari Kangas, and Jorma Laaksonen. \nSOM_PAK: The Self-Organizing Map Program Package.\n Technical Report A31, Helsinki University of Technology, Laboratory of Computer and Information Science, FIN-02150 Espoo, Finland, 1996. \nhttp://www.cis.hut.fi/research/papers/som_tr96.ps.Z\n\n\n\n\n\n\nInstallation\n\n\nJulia\n Pkg.add(\nSOM.jl\n)\n\n\n\n\n\u2013\n\n\nBecause of the package is not yet registered, it can be installed from the Julia REPL with:\n\n\nPkg.clone(\nhttps://github.com/andreasdominik/SOM.jl.git\n)\n\n\n\n\nThe package requires \nDataFrames, Distances, Distributions, ProgressMeter, StatsBase, PyPlot,\n and \nPyCall\n with the Python package \nmatplotlib\n to be installed. The requirements will be installed automatically by the package manager. Sometimes \nmatplotlib\n causes problems. The easiest way of manual installation is from the Julia REPL into the default Julia-Python environment via:\n\n\nENV[\nPYTHON\n]=\n\nPkg.add(\nConda\n)\nusing Conda\nConda.update()\n\nConda.add(\nmatplotlib\n)\nPkg.add(\nPyCall\n)\nPkg.build(\nPyCall\n)\nPkg.add(\nPyPlot\n);\n\n\n\n\n\n\nQuick Start\n\n\n\n\nQuick start: a first tutorial\n\n\n\n\n\n\nAPI\n\n\n\n\nTypes\n\n\nTraining\n\n\nKernel functions\n\n\nVisualisation\n\n\n\n\n\n\nIndex\n\n\n\n\nSOM.Som\n\n\nSOM.bubbleKernel\n\n\nSOM.classFrequencies\n\n\nSOM.gaussianKernel\n\n\nSOM.initSOM\n\n\nSOM.mapToSOM\n\n\nSOM.plotClasses\n\n\nSOM.plotDensity\n\n\nSOM.trainSOM", 
            "title": "Introduction"
        }, 
        {
            "location": "/#somjl-kohonens-self-organising-maps-for-julia", 
            "text": "The package provides training and visualisation functions for Kohonen's self-organising maps for Julia. Training functions are implemented in pure Julia, without calling external libraries.     Visualisation is implemented by using Python's MatPlotLib.", 
            "title": "SOM.jl - Kohonen's self-organising maps for Julia"
        }, 
        {
            "location": "/#self-organising-maps", 
            "text": "Self-organising maps (also referred to as SOMs or  Kohonen  maps) are artificial neural networks introduced by Teuvo Kohonen in the 1980s. Despite of their age, SOMs are still widely used as an easy and robust unsupervised learning technique for analysis and visualisation of high-dimensional data.  The SOM algorithm maps high-dimensional vectors into a lower-dimensional grid. Most often the target grid is two-dimensional, resulting into  intuitively interpretable maps.  For more details see Kohonen's papers, such as   Teuvo Kohonen,  Biological Cybernetics,   43  (1982) p. 59-69 and Teuvo Kohonen,  Biological Cybernetics,   44  (1982) p. 135-140   Technical details and background can be found in Kohonen's still relevant technical report:   Teuvo Kohonen, Jussi Hynninen, Jari Kangas, and Jorma Laaksonen.  SOM_PAK: The Self-Organizing Map Program Package.  Technical Report A31, Helsinki University of Technology, Laboratory of Computer and Information Science, FIN-02150 Espoo, Finland, 1996.  http://www.cis.hut.fi/research/papers/som_tr96.ps.Z", 
            "title": "Self-organising maps"
        }, 
        {
            "location": "/#installation", 
            "text": "Julia  Pkg.add( SOM.jl )  \u2013  Because of the package is not yet registered, it can be installed from the Julia REPL with:  Pkg.clone( https://github.com/andreasdominik/SOM.jl.git )  The package requires  DataFrames, Distances, Distributions, ProgressMeter, StatsBase, PyPlot,  and  PyCall  with the Python package  matplotlib  to be installed. The requirements will be installed automatically by the package manager. Sometimes  matplotlib  causes problems. The easiest way of manual installation is from the Julia REPL into the default Julia-Python environment via:  ENV[ PYTHON ]= \nPkg.add( Conda )\nusing Conda\nConda.update()\n\nConda.add( matplotlib )\nPkg.add( PyCall )\nPkg.build( PyCall )\nPkg.add( PyPlot );", 
            "title": "Installation"
        }, 
        {
            "location": "/#quick-start", 
            "text": "Quick start: a first tutorial", 
            "title": "Quick Start"
        }, 
        {
            "location": "/#api", 
            "text": "Types  Training  Kernel functions  Visualisation", 
            "title": "API"
        }, 
        {
            "location": "/#index", 
            "text": "SOM.Som  SOM.bubbleKernel  SOM.classFrequencies  SOM.gaussianKernel  SOM.initSOM  SOM.mapToSOM  SOM.plotClasses  SOM.plotDensity  SOM.trainSOM", 
            "title": "Index"
        }, 
        {
            "location": "/tutorials/firstTutorial/", 
            "text": "Quick start: a first tutorial\n\n\nThe concept of SOM.jl follows Kohonen's SOM_PAK software with a a 3-step approach:\n\n\n\n\ninitialise the SOM by defining topology, dimensions and random inital codebook vectors\n\n\ntrain the SOM in one or more rounds with different training parameters\n\n\nmap data into the Som and get visualisations.\n\n\n\n\nIn the following example the functions are called with a minimum set of parameters. For a description of all possible arguments see the API documentation.\n\n\n\n\nTraining data\n\n\nA first example uses the \nIris\n dataset, that comprises lengths and widths of petals and sepals of the blossoms of iris flowers of species \nIris viginica\n, \nIris setosa\n and \nIris versicolor\n. The dataset includes the 4 attributes and the correct species for 150 flowers:\n\n\niris\n150\u00d75 DataFrames.DataFrame\n\u2502 Row \u2502 SepalLength \u2502 SepalWidth \u2502 PetalLength \u2502 PetalWidth \u2502 Species   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 1   \u2502 5.1         \u2502 3.5        \u2502 1.4         \u2502 0.2        \u2502 setosa    \u2502\n\u2502 2   \u2502 4.9         \u2502 3.0        \u2502 1.4         \u2502 0.2        \u2502 setosa    \u2502\n\u2502 3   \u2502 4.7         \u2502 3.2        \u2502 1.3         \u2502 0.2        \u2502 setosa    \u2502\n\u2502 4   \u2502 4.6         \u2502 3.1        \u2502 1.5         \u2502 0.2        \u2502 setosa    \u2502\n\u2502 5   \u2502 5.0         \u2502 3.6        \u2502 1.4         \u2502 0.2        \u2502 setosa    \u2502\n\u2502 6   \u2502 5.4         \u2502 3.9        \u2502 1.7         \u2502 0.4        \u2502 setosa    \u2502\n\u2502 7   \u2502 4.6         \u2502 3.4        \u2502 1.4         \u2502 0.3        \u2502 setosa    \u2502\n...\n\n\n\n\nAs the training of self-organising maps is unsupervised, the class label (\nspecies\n) must be removed for training:\n\n\nusing SOM\nusing RDatasets\n\niris = dataset(\ndatasets\n, \niris\n)\ntrain = iris[:,1:4]\n\n\n\n\n\n\nSOM initialisation\n\n\nInitialisation sets the parameters of the SOM, such as dimensions, topology and normalisation as well as initial values of the codebook vectors.\n\n\nCalled with the minimal set of arguments, topology defaults to \nhexagonal\n and \nnot toroidal\n and normalisation to \nz-score normalisation\n with \u03bc = 0.0 and \u03c3 = 1.0. In the example, the SOM will have\n\n\n\n\nan hexagonal grid of size 10 \u00d7 8 with edges\n\n\nz-score normalised training data.\n\n\n\n\nThe training data must be provided for initialisation to derive normalisation parameters and to initialise the codes to random values within the attribute space of the dataset:\n\n\nsom = initSOM(train, 10, 8)\n\n\n\n\n\n\nTraining\n\n\nSeveral training steps can be performed with different training parameters, such as training steps and training radius. Each step returns a \nnew\n object of type Som, so that the progress of training can be analysed later. Although by default the radius decreases in the course of training, it is often advantageous to finalise the training with an additional round with small radius:\n\n\nsom = trainSOM(som, train, 10000)\nsom = trainSOM(som, train, 10000, r = 3)\n\n\n\n\n\n\nMapping of samples to the Som\n\n\nUnkonwn samples can be mapped to the SOM with the mapping function (analoguous to Kohonen's \nvisual\n). As result a vector with ID and index of the winner neuron for each sample is returned:\n\n\nwinners = mapToSOM(som, train[1:5,:])\n\n5\u00d73 DataFrames.DataFrame\n\u2502 Row \u2502 X  \u2502 Y \u2502 index \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 1   \u2502 10 \u2502 4 \u2502 40    \u2502\n\u2502 2   \u2502 8  \u2502 2 \u2502 18    \u2502\n\u2502 3   \u2502 10 \u2502 2 \u2502 20    \u2502\n\u2502 4   \u2502 9  \u2502 2 \u2502 19    \u2502\n\u2502 5   \u2502 10 \u2502 4 \u2502 40    \u2502\n\n\n\n\n\n\nVisualisation\n\n\nVisualisations include a density plot that displays the number of training samples mapped to each neuron and a classes plot that shows the class labels of training samples for every neuron as a pie chart.\n\n\nCalled without specification of a device or filename, an interactive MatPlotLib-window will be opened. If a filename is specified, a file with the respective format will be created.\n\n\nplotDensity(som)\n\nfreqs = classFrequencies(som, iris, :Species)\nplotClasses(som, freqs)\n\nplotClasses(som, freqs, fileName = \nmychart.png\n)\n\nfreqs\n80\u00d77 DataFrames.DataFrame\n\u2502 Row \u2502 index \u2502 X  \u2502 Y \u2502 Population \u2502 setosa \u2502 versicolor \u2502 virginica \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 1   \u2502 1     \u2502 1  \u2502 1 \u2502 5          \u2502 0.0    \u2502 0.0        \u2502 1.0       \u2502\n\u2502 2   \u2502 2     \u2502 2  \u2502 1 \u2502 4          \u2502 0.0    \u2502 0.0        \u2502 1.0       \u2502\n\u2502 3   \u2502 3     \u2502 3  \u2502 1 \u2502 1          \u2502 0.0    \u2502 0.0        \u2502 1.0       \u2502\n\u2502 4   \u2502 4     \u2502 4  \u2502 1 \u2502 3          \u2502 0.0    \u2502 1.0        \u2502 0.0       \u2502\n\u2502 5   \u2502 5     \u2502 5  \u2502 1 \u2502 4          \u2502 0.0    \u2502 1.0        \u2502 0.0       \u2502\n\u2502 6   \u2502 6     \u2502 6  \u2502 1 \u2502 1          \u2502 0.0    \u2502 1.0        \u2502 0.0       \u2502\n\u2502 7   \u2502 7     \u2502 7  \u2502 1 \u2502 0          \u2502 0.0    \u2502 0.0        \u2502 0.0       \u2502\n\u22ee\n\u2502 73  \u2502 73    \u2502 3  \u2502 8 \u2502 2          \u2502 0.0    \u2502 0.5        \u2502 0.5       \u2502\n\u2502 74  \u2502 74    \u2502 4  \u2502 8 \u2502 3          \u2502 0.0    \u2502 1.0        \u2502 0.0       \u2502\n\u2502 75  \u2502 75    \u2502 5  \u2502 8 \u2502 1          \u2502 0.0    \u2502 0.0        \u2502 1.0       \u2502\n\u2502 76  \u2502 76    \u2502 6  \u2502 8 \u2502 1          \u2502 0.0    \u2502 1.0        \u2502 0.0       \u2502\n\u2502 77  \u2502 77    \u2502 7  \u2502 8 \u2502 3          \u2502 0.0    \u2502 1.0        \u2502 0.0       \u2502\n\u2502 78  \u2502 78    \u2502 8  \u2502 8 \u2502 0          \u2502 0.0    \u2502 0.0        \u2502 0.0       \u2502\n\u2502 79  \u2502 79    \u2502 9  \u2502 8 \u2502 2          \u2502 1.0    \u2502 0.0        \u2502 0.0       \u2502\n\u2502 80  \u2502 80    \u2502 10 \u2502 8 \u2502 4          \u2502 1.0    \u2502 0.0        \u2502 0.0       \u2502\n\n\n\n\n\n\nSupported topologies\n\n\nDefault topology is a hexagonal grid with borders. By specifying \ntopol = :rectangular\n a rectangular grid is uses instead. For both grids an edge-less toroidal topology can be defined with \ntoroidal = true\n. In this case neurons on the edge of the SOM will neighbour the neurons on the opposite edge (simply spoken: the left is connected to the right and the top is connected with the bottom).\n\n\nIn addition spherical SOMs are possible (\ntopol = :spherical\n).\n\n\nTraining and visualisations work for all supported topologies. Please refer to the API documentation for details.", 
            "title": "Quick Start"
        }, 
        {
            "location": "/tutorials/firstTutorial/#quick-start-a-first-tutorial", 
            "text": "The concept of SOM.jl follows Kohonen's SOM_PAK software with a a 3-step approach:   initialise the SOM by defining topology, dimensions and random inital codebook vectors  train the SOM in one or more rounds with different training parameters  map data into the Som and get visualisations.   In the following example the functions are called with a minimum set of parameters. For a description of all possible arguments see the API documentation.", 
            "title": "Quick start: a first tutorial"
        }, 
        {
            "location": "/tutorials/firstTutorial/#training-data", 
            "text": "A first example uses the  Iris  dataset, that comprises lengths and widths of petals and sepals of the blossoms of iris flowers of species  Iris viginica ,  Iris setosa  and  Iris versicolor . The dataset includes the 4 attributes and the correct species for 150 flowers:  iris\n150\u00d75 DataFrames.DataFrame\n\u2502 Row \u2502 SepalLength \u2502 SepalWidth \u2502 PetalLength \u2502 PetalWidth \u2502 Species   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 1   \u2502 5.1         \u2502 3.5        \u2502 1.4         \u2502 0.2        \u2502 setosa    \u2502\n\u2502 2   \u2502 4.9         \u2502 3.0        \u2502 1.4         \u2502 0.2        \u2502 setosa    \u2502\n\u2502 3   \u2502 4.7         \u2502 3.2        \u2502 1.3         \u2502 0.2        \u2502 setosa    \u2502\n\u2502 4   \u2502 4.6         \u2502 3.1        \u2502 1.5         \u2502 0.2        \u2502 setosa    \u2502\n\u2502 5   \u2502 5.0         \u2502 3.6        \u2502 1.4         \u2502 0.2        \u2502 setosa    \u2502\n\u2502 6   \u2502 5.4         \u2502 3.9        \u2502 1.7         \u2502 0.4        \u2502 setosa    \u2502\n\u2502 7   \u2502 4.6         \u2502 3.4        \u2502 1.4         \u2502 0.3        \u2502 setosa    \u2502\n...  As the training of self-organising maps is unsupervised, the class label ( species ) must be removed for training:  using SOM\nusing RDatasets\n\niris = dataset( datasets ,  iris )\ntrain = iris[:,1:4]", 
            "title": "Training data"
        }, 
        {
            "location": "/tutorials/firstTutorial/#som-initialisation", 
            "text": "Initialisation sets the parameters of the SOM, such as dimensions, topology and normalisation as well as initial values of the codebook vectors.  Called with the minimal set of arguments, topology defaults to  hexagonal  and  not toroidal  and normalisation to  z-score normalisation  with \u03bc = 0.0 and \u03c3 = 1.0. In the example, the SOM will have   an hexagonal grid of size 10 \u00d7 8 with edges  z-score normalised training data.   The training data must be provided for initialisation to derive normalisation parameters and to initialise the codes to random values within the attribute space of the dataset:  som = initSOM(train, 10, 8)", 
            "title": "SOM initialisation"
        }, 
        {
            "location": "/tutorials/firstTutorial/#training", 
            "text": "Several training steps can be performed with different training parameters, such as training steps and training radius. Each step returns a  new  object of type Som, so that the progress of training can be analysed later. Although by default the radius decreases in the course of training, it is often advantageous to finalise the training with an additional round with small radius:  som = trainSOM(som, train, 10000)\nsom = trainSOM(som, train, 10000, r = 3)", 
            "title": "Training"
        }, 
        {
            "location": "/tutorials/firstTutorial/#mapping-of-samples-to-the-som", 
            "text": "Unkonwn samples can be mapped to the SOM with the mapping function (analoguous to Kohonen's  visual ). As result a vector with ID and index of the winner neuron for each sample is returned:  winners = mapToSOM(som, train[1:5,:])\n\n5\u00d73 DataFrames.DataFrame\n\u2502 Row \u2502 X  \u2502 Y \u2502 index \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 1   \u2502 10 \u2502 4 \u2502 40    \u2502\n\u2502 2   \u2502 8  \u2502 2 \u2502 18    \u2502\n\u2502 3   \u2502 10 \u2502 2 \u2502 20    \u2502\n\u2502 4   \u2502 9  \u2502 2 \u2502 19    \u2502\n\u2502 5   \u2502 10 \u2502 4 \u2502 40    \u2502", 
            "title": "Mapping of samples to the Som"
        }, 
        {
            "location": "/tutorials/firstTutorial/#visualisation", 
            "text": "Visualisations include a density plot that displays the number of training samples mapped to each neuron and a classes plot that shows the class labels of training samples for every neuron as a pie chart.  Called without specification of a device or filename, an interactive MatPlotLib-window will be opened. If a filename is specified, a file with the respective format will be created.  plotDensity(som)\n\nfreqs = classFrequencies(som, iris, :Species)\nplotClasses(som, freqs)\n\nplotClasses(som, freqs, fileName =  mychart.png )\n\nfreqs\n80\u00d77 DataFrames.DataFrame\n\u2502 Row \u2502 index \u2502 X  \u2502 Y \u2502 Population \u2502 setosa \u2502 versicolor \u2502 virginica \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 1   \u2502 1     \u2502 1  \u2502 1 \u2502 5          \u2502 0.0    \u2502 0.0        \u2502 1.0       \u2502\n\u2502 2   \u2502 2     \u2502 2  \u2502 1 \u2502 4          \u2502 0.0    \u2502 0.0        \u2502 1.0       \u2502\n\u2502 3   \u2502 3     \u2502 3  \u2502 1 \u2502 1          \u2502 0.0    \u2502 0.0        \u2502 1.0       \u2502\n\u2502 4   \u2502 4     \u2502 4  \u2502 1 \u2502 3          \u2502 0.0    \u2502 1.0        \u2502 0.0       \u2502\n\u2502 5   \u2502 5     \u2502 5  \u2502 1 \u2502 4          \u2502 0.0    \u2502 1.0        \u2502 0.0       \u2502\n\u2502 6   \u2502 6     \u2502 6  \u2502 1 \u2502 1          \u2502 0.0    \u2502 1.0        \u2502 0.0       \u2502\n\u2502 7   \u2502 7     \u2502 7  \u2502 1 \u2502 0          \u2502 0.0    \u2502 0.0        \u2502 0.0       \u2502\n\u22ee\n\u2502 73  \u2502 73    \u2502 3  \u2502 8 \u2502 2          \u2502 0.0    \u2502 0.5        \u2502 0.5       \u2502\n\u2502 74  \u2502 74    \u2502 4  \u2502 8 \u2502 3          \u2502 0.0    \u2502 1.0        \u2502 0.0       \u2502\n\u2502 75  \u2502 75    \u2502 5  \u2502 8 \u2502 1          \u2502 0.0    \u2502 0.0        \u2502 1.0       \u2502\n\u2502 76  \u2502 76    \u2502 6  \u2502 8 \u2502 1          \u2502 0.0    \u2502 1.0        \u2502 0.0       \u2502\n\u2502 77  \u2502 77    \u2502 7  \u2502 8 \u2502 3          \u2502 0.0    \u2502 1.0        \u2502 0.0       \u2502\n\u2502 78  \u2502 78    \u2502 8  \u2502 8 \u2502 0          \u2502 0.0    \u2502 0.0        \u2502 0.0       \u2502\n\u2502 79  \u2502 79    \u2502 9  \u2502 8 \u2502 2          \u2502 1.0    \u2502 0.0        \u2502 0.0       \u2502\n\u2502 80  \u2502 80    \u2502 10 \u2502 8 \u2502 4          \u2502 1.0    \u2502 0.0        \u2502 0.0       \u2502", 
            "title": "Visualisation"
        }, 
        {
            "location": "/tutorials/firstTutorial/#supported-topologies", 
            "text": "Default topology is a hexagonal grid with borders. By specifying  topol = :rectangular  a rectangular grid is uses instead. For both grids an edge-less toroidal topology can be defined with  toroidal = true . In this case neurons on the edge of the SOM will neighbour the neurons on the opposite edge (simply spoken: the left is connected to the right and the top is connected with the bottom).  In addition spherical SOMs are possible ( topol = :spherical ).  Training and visualisations work for all supported topologies. Please refer to the API documentation for details.", 
            "title": "Supported topologies"
        }, 
        {
            "location": "/api/types/", 
            "text": "Types\n\n\n#\n\n\nSOM.Som\n \n \nType\n.\n\n\nstruct Som\n\n\n\n\nStructure to hold all data of a trained SOM.\n\n\nFields:\n\n\n\n\ncodes::Array{Float64,2}\n: 2D-array of codebook vectors. One vector per row\n\n\ncolNames::Array{String,1}\n: names of the attribute with which the SOM is trained\n\n\nnormParams::DataFrame\n: normalisation parameters for each column               of training data. Column headers corresponds with               colNames.\n\n\nnorm::Symbol\n: normalisation type; one of \n:none, :minmax, :zscore\n\n\nxdim::Int\n: number of neurons in x-direction\n\n\nydim::Int\n: number of neurons in y-direction\n\n\nnCodes::Int\n: total number of neurons\n\n\ngrid::Array{Float64,2}\n: 2D-array of coordinates of neurons on the map         (2 columns (x,y)] for rectangular and hexagonal maps          3 columns (x,y,z) for spherical maps)\n\n\nindices::DataFrame\n: X-, Y-indices of the neurons\n\n\ntopol::Symbol\n: topology of the SOM; one of \n:rectangular, :hexagonal, :spherical\n\n\ntoroidal::Bool\n: if \ntrue\n, the SOM is toroidal (has no edges)\n\n\npopulation::Array{Int,1}\n: 1D-array of numbers of training samples mapped to               each neuron.\n\n\n\n\nsource", 
            "title": "Types"
        }, 
        {
            "location": "/api/types/#types", 
            "text": "#  SOM.Som     Type .  struct Som  Structure to hold all data of a trained SOM.  Fields:   codes::Array{Float64,2} : 2D-array of codebook vectors. One vector per row  colNames::Array{String,1} : names of the attribute with which the SOM is trained  normParams::DataFrame : normalisation parameters for each column               of training data. Column headers corresponds with               colNames.  norm::Symbol : normalisation type; one of  :none, :minmax, :zscore  xdim::Int : number of neurons in x-direction  ydim::Int : number of neurons in y-direction  nCodes::Int : total number of neurons  grid::Array{Float64,2} : 2D-array of coordinates of neurons on the map         (2 columns (x,y)] for rectangular and hexagonal maps          3 columns (x,y,z) for spherical maps)  indices::DataFrame : X-, Y-indices of the neurons  topol::Symbol : topology of the SOM; one of  :rectangular, :hexagonal, :spherical  toroidal::Bool : if  true , the SOM is toroidal (has no edges)  population::Array{Int,1} : 1D-array of numbers of training samples mapped to               each neuron.   source", 
            "title": "Types"
        }, 
        {
            "location": "/api/soms/", 
            "text": "Training\n\n\n#\n\n\nSOM.initSOM\n \n \nFunction\n.\n\n\ninitSOM(train, xdim, ydim = xdim;  norm = :zscore, topol = :hexagonal,\n        toroidal = false)\n\n\n\n\nInitialises a SOM.\n\n\nArguments:\n\n\n\n\ntrain\n: training data\n\n\nxdim, ydim\n: geometry of the SOM          If DataFrame, the column names will be used as attribute names.          Codebook vectors will be sampled from the training data.          for spherical SOMs ydim can be omitted.\n\n\nnorm\n: optional normalisation; one of :\nminmax, :zscore or :none\n\n\ntopol\n: topology of the SOM; one of \n:rectangular, :hexagonal or :spherical\n.\n\n\ntoroidal\n: optional flag; if true, the SOM is toroidal.\n\n\n\n\nsource\n\n\n#\n\n\nSOM.trainSOM\n \n \nFunction\n.\n\n\ntrainSOM(som::Som, train::Any, len;\n         \u03b7 = 0.2 kernel = gaussianKernel,\n         r = 0.0, rDecay = true, \u03b7Decay = true)\n\n\n\n\nTrain an initialised or pre-trained SOM.\n\n\nArguments:\n\n\n\n\nsom\n: object of type Som with a trained som\n\n\ntrain\n: training data\n\n\nlen\n: number of single training steps (\nnot\n epochs)\n\n\n\u03b7\n: learning rate\n\n\nkernel::function\n: optional distance kernel; one of (\nbubbleKernel, gaussianKernel\n)           default is \ngaussianKernel\n\n\nr\n: optional training radius.      If r is not specified, it defaults to \u221a(xdim^2 + ydim^2) / 2\n\n\nrDecay\n: optional flag; if true, r decays to 0.0 during the training.\n\n\n\u03b7Decay\n: optional flag; if true, learning rate \u03b7 decays to 0.0           during the training.\n\n\n\n\nTraining data must be convertable to Array{Float64,2} with \nconvert()\n. Training samples are row-wise; one sample per row.\n\n\nsource\n\n\n#\n\n\nSOM.mapToSOM\n \n \nFunction\n.\n\n\nmapToSOM(som::Som, data)\n\n\n\n\nReturn a DataFrame with X-, Y-indices and index of winner neuron for every row in data.\n\n\nArguments\n\n\n\n\nsom\n: a trained SOM\n\n\ndata\n: Array or DataFrame with training data.\n\n\n\n\nData must have the same number of dimensions as the training dataset and will be normalised with the same parameters.\n\n\nsource\n\n\n#\n\n\nSOM.classFrequencies\n \n \nFunction\n.\n\n\nclassFrequencies(som::Som, data, classes)\n\n\n\n\nReturn a DataFrame with class frequencies for all neurons.\n\n\nArguments:\n\n\n\n\nsom\n: a trained SOM\n\n\ndata\n: data with row-wise samples and class information in each row\n\n\nclasses\n: Name of column with class information.\n\n\n\n\nData must have the same number of dimensions as the training dataset. The column with class labels is given as \nclasses\n (name or index). Returned DataFrame has the columns:\n\n\n\n\nX-, Y-indices and index: of winner neuron for every row in data\n\n\npopulation: number of samples mapped to the neuron\n\n\nfrequencies: one column for each class label.\n\n\n\n\nsource\n\n\n\n\nKernel functions\n\n\n#\n\n\nSOM.bubbleKernel\n \n \nFunction\n.\n\n\nbubbleKernel(x, r)\n\n\n\n\nReturn 1.0 if dist \n= r, otherwise 0.0.\n\n\nsource\n\n\n#\n\n\nSOM.gaussianKernel\n \n \nFunction\n.\n\n\ngaussianKernel(x, r)\n\n\n\n\nReturn Gaussian(x) for \u03bc=0.0 and \u03c3 = r/3.\n\n\nsource", 
            "title": "Training"
        }, 
        {
            "location": "/api/soms/#training", 
            "text": "#  SOM.initSOM     Function .  initSOM(train, xdim, ydim = xdim;  norm = :zscore, topol = :hexagonal,\n        toroidal = false)  Initialises a SOM.  Arguments:   train : training data  xdim, ydim : geometry of the SOM          If DataFrame, the column names will be used as attribute names.          Codebook vectors will be sampled from the training data.          for spherical SOMs ydim can be omitted.  norm : optional normalisation; one of : minmax, :zscore or :none  topol : topology of the SOM; one of  :rectangular, :hexagonal or :spherical .  toroidal : optional flag; if true, the SOM is toroidal.   source  #  SOM.trainSOM     Function .  trainSOM(som::Som, train::Any, len;\n         \u03b7 = 0.2 kernel = gaussianKernel,\n         r = 0.0, rDecay = true, \u03b7Decay = true)  Train an initialised or pre-trained SOM.  Arguments:   som : object of type Som with a trained som  train : training data  len : number of single training steps ( not  epochs)  \u03b7 : learning rate  kernel::function : optional distance kernel; one of ( bubbleKernel, gaussianKernel )           default is  gaussianKernel  r : optional training radius.      If r is not specified, it defaults to \u221a(xdim^2 + ydim^2) / 2  rDecay : optional flag; if true, r decays to 0.0 during the training.  \u03b7Decay : optional flag; if true, learning rate \u03b7 decays to 0.0           during the training.   Training data must be convertable to Array{Float64,2} with  convert() . Training samples are row-wise; one sample per row.  source  #  SOM.mapToSOM     Function .  mapToSOM(som::Som, data)  Return a DataFrame with X-, Y-indices and index of winner neuron for every row in data.  Arguments   som : a trained SOM  data : Array or DataFrame with training data.   Data must have the same number of dimensions as the training dataset and will be normalised with the same parameters.  source  #  SOM.classFrequencies     Function .  classFrequencies(som::Som, data, classes)  Return a DataFrame with class frequencies for all neurons.  Arguments:   som : a trained SOM  data : data with row-wise samples and class information in each row  classes : Name of column with class information.   Data must have the same number of dimensions as the training dataset. The column with class labels is given as  classes  (name or index). Returned DataFrame has the columns:   X-, Y-indices and index: of winner neuron for every row in data  population: number of samples mapped to the neuron  frequencies: one column for each class label.   source", 
            "title": "Training"
        }, 
        {
            "location": "/api/soms/#kernel-functions", 
            "text": "#  SOM.bubbleKernel     Function .  bubbleKernel(x, r)  Return 1.0 if dist  = r, otherwise 0.0.  source  #  SOM.gaussianKernel     Function .  gaussianKernel(x, r)  Return Gaussian(x) for \u03bc=0.0 and \u03c3 = r/3.  source", 
            "title": "Kernel functions"
        }, 
        {
            "location": "/api/visualisations/", 
            "text": "Visualisation\n\n\n#\n\n\nSOM.plotDensity\n \n \nFunction\n.\n\n\nplotDensity(som::Som; predict = nothing,\n            title = \nDensity of Self-Organising Map\n,\n            paper = :a4r,\n            colormap = \nautumn_r\n,\n            detail = 45,\n            device = :display, fileName = \nsomplot\n)\n\n\n\n\nPlot the population of neurons as colours.\n\n\nArguments:\n\n\n\n\nsom\n: the som of type \nSom\n; som is the only mandatory argument\n\n\npredict\n: DataFrame of mappings as outputed by \nmapToSOM()\n\n\ntitle\n: main title of plot\n\n\npaper\n: plot size; currentlx supported: \n:a4, :a4r, :letter, :letterr\n\n\ncolormap\n: MatPlotLib colourmap (Python-style strings; e.g. \n\"Greys\"\n).\n\n\ndetail\n: only relevant for 3D-plotting of spherical SOMs: higher           values result in smoother display of the 3D-sphere\n\n\ndevice\n: one of \n:display, :png, :svg, :pdf\n or any file-type supported           by MatPlotLib; default is \n:display\n\n\nfileName\n: name of image file. File extention overrides the setting of             \ndevice\n.\n\n\n\n\nsource\n\n\n#\n\n\nSOM.plotClasses\n \n \nFunction\n.\n\n\nplotClasses(som::Som, frequencies;\n            title = \nClass Frequencies of Self-Organising Map\n,\n            paper = :a4r,\n            colors = \nbrg\n,\n            detail = 45,\n            device = :display, fileName = \nsomplot\n)\n\n\n\n\nPlot the population of neurons as colours.\n\n\nArguments:\n\n\n\n\nsom\n: the som of type \nSom\n; som is the only mandatory argument\n\n\nfrequencies\n: DataFrame of frequencies as outputed by classFrequencies()\n\n\ntitle\n: main title of plot\n\n\npaper\n: plot size; currentlx supported: \n:a4, :a4r, :letter, :letterr\n\n\ncolors\n: MatPlotLib colourmap (Python-style as string \n\"gray\"\n or             Julia-style as Symbol \n:gray\n) \nor\n dictionary with             classes as keys and colours as vals; default: \nbrg\n\n\ndetail\n: only relevant for 3D-plotting of spherical SOMs: higher           values result in smoother display of the 3D-sphere\n\n\ndevice\n: one of \n:display, :png, :svg, :pdf\n or any file-type supported           by MatPlotLib; default is \n:display\n\n\nfileName\n: name of image file. File extention overrides the setting of             \ndevice\n.\n\n\n\n\nsource", 
            "title": "Visualisation"
        }, 
        {
            "location": "/api/visualisations/#visualisation", 
            "text": "#  SOM.plotDensity     Function .  plotDensity(som::Som; predict = nothing,\n            title =  Density of Self-Organising Map ,\n            paper = :a4r,\n            colormap =  autumn_r ,\n            detail = 45,\n            device = :display, fileName =  somplot )  Plot the population of neurons as colours.  Arguments:   som : the som of type  Som ; som is the only mandatory argument  predict : DataFrame of mappings as outputed by  mapToSOM()  title : main title of plot  paper : plot size; currentlx supported:  :a4, :a4r, :letter, :letterr  colormap : MatPlotLib colourmap (Python-style strings; e.g.  \"Greys\" ).  detail : only relevant for 3D-plotting of spherical SOMs: higher           values result in smoother display of the 3D-sphere  device : one of  :display, :png, :svg, :pdf  or any file-type supported           by MatPlotLib; default is  :display  fileName : name of image file. File extention overrides the setting of              device .   source  #  SOM.plotClasses     Function .  plotClasses(som::Som, frequencies;\n            title =  Class Frequencies of Self-Organising Map ,\n            paper = :a4r,\n            colors =  brg ,\n            detail = 45,\n            device = :display, fileName =  somplot )  Plot the population of neurons as colours.  Arguments:   som : the som of type  Som ; som is the only mandatory argument  frequencies : DataFrame of frequencies as outputed by classFrequencies()  title : main title of plot  paper : plot size; currentlx supported:  :a4, :a4r, :letter, :letterr  colors : MatPlotLib colourmap (Python-style as string  \"gray\"  or             Julia-style as Symbol  :gray )  or  dictionary with             classes as keys and colours as vals; default:  brg  detail : only relevant for 3D-plotting of spherical SOMs: higher           values result in smoother display of the 3D-sphere  device : one of  :display, :png, :svg, :pdf  or any file-type supported           by MatPlotLib; default is  :display  fileName : name of image file. File extention overrides the setting of              device .   source", 
            "title": "Visualisation"
        }, 
        {
            "location": "/LICENSE/", 
            "text": "The SOM.jl package is licensed under the MIT \"Expat\" License:\n\n\n\n\nCopyright (c) 2018: Andreas Dominik.\n\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n\n\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.", 
            "title": "License"
        }
    ]
}